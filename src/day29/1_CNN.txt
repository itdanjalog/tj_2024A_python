합성곱 신경망 # Convolutional Neural Network # 컨볼루셔널 뉴럴 네트워크
    - CNN은 합성곱 연산(Convolution)과 풀링(Pooling)이라는 두 가지 주요 개념을 바탕으로 하며,
    이미지나 영상과 같은 데이터에서 특징을 추출하고 학습하는 데 강력한 성능을 발휘합니다.

    - 이미지를 인식할 수 있는 능력을 모델이 갖추게 된다.

    - CNN은 보통 입력층, 합성곱층(Convolutional Layer), 풀링층(Pooling Layer),
    그리고 **완전 연결층(Fully Connected Layer)**으로 구성됩니다.

    - 중요개념 : 합성곱 , 커널(필터) , 특징 맵 , 패딩 , 스트라이드 , 폴링
    CNN은 이미지 데이터를 처리할 때 수작업으로 특징을 정의할 필요 없이, 중요한 패턴을 자동으로 학습합니다.
    이 자동화된 특징 추출 과정은 CNN이 이미지 인식, 객체 탐지, 영상 처리 등 다양한 분야에서 뛰어난 성능을 발휘하는 이유입니다.

    - CNN의 구조
        1. 입력층(Input Layer): 원본 이미지 데이터를 입력으로 받습니다
         예를 들어 32×32 크기의 이미지라면 픽셀 값을 이차원 배열로 입력합니다.
        2. 합성곱층(Convolutional Layer): 이미지 위에 필터(커널)를 적용해 중요한
        패턴이나 특징(예: 가장자리, 질감)을 추출합니다. 필터는 특정 패턴을 감지하는 역할을 합니다.
        3. 풀링층(Pooling Layer): 이미지 크기를 줄여 계산량을 줄이고, 중요하지 않은 세부 정보를 무시하여 모델의 성능을 높입니다.
        주로 최대 풀링(Max Pooling)을 사용해 가장 큰 값을 선택합니다.
        4. 완전 연결층(Fully Connected Layer) : CNN의 마지막에 있는 층으로, 추출한 특징을 바탕으로 분류나 예측을 수행합니다.
        일반적인 인공신경망처럼 모든 뉴런이 서로 연결됩니다.
        5.출력층(Output Layer): 최종 예측을 제공합니다
        예를 들어 이미지 분류 문제에서는 각 클래스(예: 고양이, 강아지)에 대한 확률이 출력됩니다.
    -
    공간적 정보 유지: CNN은 이미지 내에서의 공간적 구조를 유지한 채로 패턴을 추출합니다. 전통적인 신경망은 모든 픽셀을 평탄화(flatten)하여 위치 정보를 잃을 수 있지만, CNN은 위치 관계를 고려한 학습이 가능하여 이미지에서 더 의미 있는 정보 추출이 가능합니다.
    파라미터 효율성: CNN은 전통적인 신경망보다 훨씬 적은 파라미터로 학습할 수 있습니다. 커널(필터)은 이미지를 전체적으로 학습하는 것이 아니라 작은 부분들을 학습하여, 데이터가 커도 효율적인 학습이 가능합니다.
    자동 특징 추출: CNN은 자동으로 이미지에서 가장 중요한 특징(엣지, 패턴, 형태 등)을 추출합니다. 사람의 개입 없이 이미지에서 어떤 특징을 볼지 미리 정의할 필요가 없습니다.
    다양한 적용 분야: CNN은 이미지 분류 외에도 객체 탐지(Object Detection), 얼굴 인식(Face Recognition), 이미지 생성(Generative Tasks), 영상 분석 등 다양한 분야에서 뛰어난 성능을 보입니다.

    -생활 속 예시
        스마트폰 얼굴 인식, 자동차 자율 주행, 의료 영상 분석,스마트 홈 디바이스,사진 필터

합성곱(Convolution)
    - 합성곱 신경망(CNN, Convolutional Neural Network)**의 핵심 연산 중 하나
    - 이미지와 필터(또는 커널)를 결합하여 중요한 특징을 추출하는 방식
    - 합성곱의 원리
    1. 필터(커널): 작은 크기의 행렬(예: 3x3, 5x5)로, 이 필터는 이미지의 작은 영역과 곱셈 및 덧셈 연산을 수행하여 새로운 값을 생성합니다.
    2. 스트라이드(Strides): 필터가 이미지 위에서 이동하는 간격을 의미합니다. 스트라이드가 1이면 한 픽셀씩 이동하고, 스트라이드가 2이면 두 픽셀씩 이동하여 더 빠른 처리가 가능하게 합니다.
    3. 패딩(Padding): 필터가 이미지 가장자리를 벗어나지 않도록, 이미지를 둘러싼 테두리에 0으로 채워넣는 기법입니다. 이를 통해 이미지 크기를 유지하거나 특징 손실을 방지할 수 있습니다.


커널(필터)
    - 커널은 보통 2D 형태를 가지며 작은 크기의 행렬로, 주로 3×3 또는 5×5 크기의 필터가 사용됩니다.
    이 필터는 이미지의 작은 부분과 곱셈 및 덧셈을 통해 새로운 값을 생성합니다.
    커널의 작동 원리
합성곱 연산: 커널은 입력 이미지 위를 슬라이딩하며(스트라이드), 각 위치에서 이미지의 픽셀 값과 커널의 값 간의 요소별 곱셈을 수행한 후 이 값을 합산합니다. 이를 통해 새로운 출력 값을 생성합니다.
특징 맵 생성: 커널이 이미지의 모든 위치에 대해 이러한 합성곱 연산을 수행하면, 각 커널에 대한 **특징 맵(Feature Map)**이 생성됩니다. 각 특징 맵은 특정한 패턴이나 특징(예: 가장자리, 선, 질감 등)을 나타냅니다.
학습 가능한 파라미터: CNN에서 커널의 값은 학습 과정 중에 최적화됩니다. 즉, 초기에는 무작위로 설정되지만, 역전파(Backpropagation) 과정을 통해 손실을 최소화하는 방향으로 조정됩니다.


역전파
    - 역전파 알고리즘은 신경망의 학습을 위한 핵심 기법으로, 모델이 출력값을 목표값에 가깝게 조정할 수 있도록 가중치를 업데이트하는 방법입니다. 이 과정은 손실 함수의 기울기를 계산하고, 이를 통해 각 가중치의 기여도를 분석하여 모델의 성능을 향상시키는 데 필수적입니다.
    - 인공 신경망에서 학습을 수행하는 데 사용되는 알고리즘으로, 네트워크의 가중치를 업데이트하기 위해 손실 함수의 기울기를 계산하는 과정

가중치
인공 신경망에서 입력 데이터의 중요성을 나타내는 파라미터입니다. 신경망의 각 뉴런에서 입력값에 가중치를 곱한 후, 그 결과를 활성화 함수에 통과시켜 다음 뉴런으로 전달하는 방식으로 작동합니다. 가중치는 모델이 학습하는 동안 업데이트되며, 데이터의 특정 패턴을 학습하는 데 중요한 역할을 합니다.

가중치의 역할
입력 데이터의 중요도 반영: 각 입력값에 대해 가중치를 조정함으로써 모델은 특정 입력이 결과에 미치는 영향을 조절할 수 있습니다. 높은 가중치는 해당 입력이 중요하다는 것을 의미하며, 낮은 가중치는 그 반대입니다.
학습 과정에서의 조정: 가중치는 학습 과정 중에 조정됩니다. 초기에는 무작위로 설정되지만, 역전파(backpropagation) 알고리즘을 통해 손실 함수의 기울기를 계산하고, 이를 기반으로 가중치가 업데이트됩니다. 이 과정을 통해 모델은 입력과 출력 간의 관계를 학습합니다.
결정 경계 형성: 가중치는 신경망이 데이터의 패턴을 학습하여 결정 경계를 형성하는 데 도움을 줍니다. 예를 들어, 이진 분류 문제에서 신경망이 입력 데이터를 두 개의 클래스로 나누는 기준을 설정하는 데 사용됩니다.

예]
영화 추천 시스템 : 스트리밍 서비스에서 사용자의 취향을 분석하여 영화나 TV 프로그램을 추천할 때, 다양한 요소(장르, 평점, 감독 등)에 가중치를 부여합니다. 예를 들어, 사용자가 특정 장르의 영화를 더 선호한다면, 해당 장르에 더 높은 가중치를 두어 추천 목록을 생성합니다.
성적 평가 : 학생의 성적을 평가할 때, 각 과목의 중요성에 따라 가중치를 다르게 부여할 수 있습니다. 예를 들어, 수학이 과학 분야 진로에 더 중요하다면, 수학 성적에 더 높은 가중치를 부여하여 최종 성적을 계산합니다.

관계 요약
가중치는 신경망의 중요한 파라미터로, 모델의 성능에 직접적인 영향을 미칩니다.
역전파는 손실 함수에 대한 가중치의 기울기를 계산하여 가중치 업데이트를 위한 정보를 제공합니다. 즉, 역전파를 통해 각 가중치가 손실에 얼마나 기여하는지를 알 수 있습니다.
경사 하강법은 역전파에서 계산된 기울기를 사용하여 가중치를 업데이트합니다. 이 과정이 반복됨으로써 가중치는 점진적으로 최적의 값으로 조정되어 신경망의 성능이 향상됩니다.

전체적인 흐름
입력 데이터가 네트워크를 통과하여 출력을 생성합니다.
출력과 실제 목표값 간의 차이를 계산하여 손실을 구합니다.
역전파를 통해 손실 함수에 대한 각 가중치의 기울기를 계산합니다.
경사 하강법을 사용하여 가중치를 업데이트합니다.
이 과정을 반복하여 신경망의 성능을 최적화합니다.


[ 이미지 채널 ]
정의: 이미지 채널은 색상 정보를 담고 있는 각 구성 요소를 나타냅니다. 예를 들어, RGB 색상 모델에서는 빨강(R), 초록(G), 파랑(B) 세 가지 기본 색상 채널이 있습니다. 이 세 채널이 결합되어 다양한 색상을 표현합니다.

예시:
흑백 이미지: 1채널(회색조)
컬러 이미지: 3채널(RGB) 또는 4채널(RGBA, 알파 채널 포함)

[ 스트라이드 ]
스트라이드는 필터가 한 번에 몇 픽셀을 이동하는지를 결정하며, 이미지의 크기와 특성 맵(feature map)의 크기를 조정하는 데 중요한 역할을 합니다.
: 필터가 입력 데이터에서 이동하는 픽셀 수를 의미합니다. 예를 들어, 스트라이드가 1이라면 필터는 한 픽셀씩 이동하고, 스트라이드가 2라면 두 픽셀씩 이동합니다.

스트라이드 가 높은게 좋은거야?
스트라이드의 크기는 사용하려는 모델의 목적과 데이터의 특성에 따라 조정되어야 합니다. 높은 스트라이드는 계산 효율성과 일반화에 유리하지만,
세부 정보 손실이 우려됩니다. 반면, 낮은 스트라이드는 더 많은 세부 정보를 유지하지만 계산 비용이 증가하고 과적합의 위험이 있습니다. 따라서 특정 문제에 맞는 최적의 스트라이드 크기를 선택하는 것이 중요합니다.

[ 패딩 ]

패딩: 입력 데이터의 가장자리에 추가하는 픽셀로, 일반적으로 0으로 채워진 픽셀입니다. 이를 통해 합성곱 연산이 더 매끄럽게 이루어질 수 있도록 합니다.
특성 맵 크기 유지:
패딩을 사용하면 입력 이미지의 크기를 유지할 수 있습니다. 예를 들어, 필터가 이미지의 가장자리에서 적용될 때, 패딩을 추가하면 필터가 이미지의 모든 부분을 고르게 처리할 수 있습니다.
정보 손실 방지:
이미지의 가장자리에 있는 픽셀은 종종 중요한 정보를 포함하고 있습니다. 패딩을 추가하면 이러한 가장자리 정보가 손실되는 것을 방지할 수 있습니다.
학습 안정성 향상:
패딩은 CNN의 학습 안정성을 높이고, 경계 효과(edge effect)를 줄여 줍니다. 경계 효과란 필터가 이미지의 가장자리를 처리할 때 발생할 수 있는 왜곡을 의미합니다.
연산 효율성:
패딩을 통해 네트워크의 구조를 조정하여, 더 깊은 네트워크를 설계할 수 있으며, 이는 더 복잡한 패턴을 학습하는 데 도움을 줍니다.

[ 폴링 ]
폴링: 필터를 사용하여 입력 데이터의 작은 영역에서 특정 통계 값을 계산하여 크기를 줄이는 과정입니다.
예를 들어, 2x2 크기의 풀링 필터를 사용하면 해당 영역의 최대값이나 평균값을 선택하여 그 영역을 하나의 값으로 대체합니다.

특징 추출:
폴링은 입력 데이터에서 중요한 특징을 추출하고 강조하는 데 도움을 줍니다. 최대 풀링의 경우, 각 영역에서 가장 큰 값을 선택함으로써 중요한 정보를 보존합니다.
차원 축소:
폴링을 통해 특성 맵의 크기를 줄이면 계산량과 메모리 사용량이 감소합니다. 이는 모델의 학습과 추론 속도를 높이고, 더 깊은 네트워크를 설계할 수 있게 합니다.
불변성 향상:
폴링은 입력 데이터의 작은 변동(예: 위치 이동, 회전 등)에 대해 불변성을 제공합니다. 이는 네트워크가 더 일반화된 특징을 학습하는 데 도움을 줍니다.
과적합 방지:
폴링은 모델이 훈련 데이터에 과적합(overfitting)되는 것을 방지하는 데 도움을 줄 수 있습니다. 더 작은 특성 맵을 사용하여 모델의 복잡성을 줄이기 때문입니다.

바이-스
Bias는 신경망에서 각 뉴런의 출력에 더해지는 상수 값으로, 모델의 유연성을 높이고 다양한 패턴을 학습하는 데 도움을 줍니다. 생활 속 다양한 예시에서 Bias의 개념은 기본값을 설정하는 데 사용되며, 이를 통해 더 정확하고 복잡한 예측을 가능하게 합니다.
Bias는 신경망에서 각 뉴런의 출력에 더해지는 상수 값으로, y절편과 유사한 역할을 합니다


특징
특징은 어떤 물체나 이미지를 설명하는 중요한 부분이나 성질이에요. 예를 들어, 우리가 물체를 보고 그 물체가 무엇인지 알아차리는 데 도움을 주는 정보들입니다.

예시로 이해하기
모서리와 선:

생각해보세요! 우리가 집에 있는 종이에 사각형을 그릴 때, 사각형의 네 모서리를 보겠죠? 그 모서리가 바로 특징이에요.
합성곱 레이어의 필터는 모서리를 감지하는 데 특화되어 있어서, 이미지에서 사각형이나 다른 형태를 찾아낼 수 있어요.
색상과 질감:

우리가 좋아하는 티셔츠를 입을 때, 그 티셔츠의 색깔과 질감이 있잖아요? 예를 들어, 매끈한 느낌의 티셔츠와 거친 느낌의 티셔츠가 있어요.
합성곱 레이어는 이런 색상과 질감을 특징으로 인식해요. 예를 들어, 물방울 무늬가 있는 티셔츠를 보고 이 티셔츠의 특징을 잘 잡아낼 수 있죠.
얼굴 인식:

사람의 얼굴을 볼 때, 우리는 눈, 코, 입의 모양을 보고 "아, 저 사람은 나의 친구야!"라고 알 수 있어요.
합성곱 레이어의 필터는 눈, 코, 입 같은 얼굴의 특징을 감지하는 데 도움을 줘서, 컴퓨터가 얼굴을 인식할 수 있도록 해줍니다.
어떻게 작동할까?
필터의 역할:

필터는 마치 특별한 안경처럼 작용해요. 이 안경을 통해 우리가 보고 있는 이미지에서 중요한 특징(모서리, 질감 등)을 찾아내요.
필터는 이미지를 한 부분씩 차례로 살펴보며, 그 부분에서 어떤 특징이 있는지를 판단해요.
활성화 맵:

필터가 이미지를 살펴보면서 중요한 특징을 발견하면, 그것을 기록해요. 이 기록을 활성화 맵이라고 해요.
활성화 맵은 이미지의 어떤 부분이 특징인지 알려주는 일종의 지도 같은 거예요.

활성화 맵(특성 맵) 설명
이 맵은 입력 이미지의 특정 부분에서 필터가 감지한 특징의 강도를 나타냅니다.























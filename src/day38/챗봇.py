# 대화 데이터
# data = {
#     "안녕하세요": "안녕! 어떻게 도와줄까?",
#     "너의 이름은 뭐야": "나는 간단한 챗봇이야.",
#     "날씨 어때": "나는 날씨를 알 수 없어, 하지만 좋은 날 되길 바래!",
#     "잘 가": "안녕히 가!",
#     "오늘 기분 어때": "나는 항상 좋아!",
#     "무슨 일을 해": "나는 너랑 대화하는 챗봇이야.",
#     "좋아하는 색은 뭐야": "나는 파란색을 좋아해!",
#     "취미가 뭐야": "나는 대화하는 걸 좋아해.",
#     "가장 좋아하는 음식은 뭐야": "나는 음식을 먹지 않지만, 피자를 좋아해!",
#     "어디서 살아": "나는 클라우드에서 살고 있어.",
#     "가족이 있어": "나는 혼자야.",
#     "언제 태어났어": "나는 만들어진 지 얼마 되지 않았어.",
#     "가장 좋아하는 영화는 뭐야": "나는 '인셉션'을 좋아해!",
#     "책 읽어": "나는 책을 읽지 않지만, 많은 정보를 알고 있어.",
#     "최신 기술 트렌드는 뭐야": "인공지능이 매우 핫한 주제야.",
#     "주말에는 뭐 해": "나는 항상 너랑 대화해.",
#     "여행 가고 싶어": "어디로 가고 싶어?",
#     "최고의 여행지는 어디야": "유럽이 아름다운 곳으로 유명해.",
#     "좋아하는 계절은 뭐야": "나는 모든 계절을 좋아해!",
#     "가장 좋아하는 운동은 뭐야": "나는 운동을 하지 않지만, 축구를 좋아해.",
#     "자주 사용하는 앱은 뭐야": "나는 대화 앱을 자주 사용해.",
#     "인생의 의미는 뭐야": "각자의 해답이 다를 수 있어.",
#     "꿈은 뭐야": "나는 너의 꿈을 듣는 게 꿈이야.",
#     "어떤 음악을 좋아해": "나는 다양한 음악을 좋아해.",
#     "최신 음악 추천해 줘": "최근에는 BTS의 노래가 인기가 많아.",
#     "가장 좋아하는 동물은 뭐야": "나는 고양이를 좋아해!",
#     "시간이 얼마 남았어": "시간은 항상 흐르고 있어.",
#     "이해할 수 없어": "미안, 더 자세히 설명해 줘.",
#     "기술이 미래를 바꿀까": "응, 기술은 많은 변화를 가져올 수 있어.",
#     "AI에 대해 어떻게 생각해": "AI는 흥미로운 주제야!",
#     "인간과 AI의 차이는 뭐야": "AI는 감정을 가지지 않지만, 데이터를 처리해.",
#     "사람과 대화하는 게 좋아": "응, 대화하는 것이 즐거워.",
#     "어떤 질문이든 대답할 수 있어": "최선을 다해 대답할게.",
#     "언제든지 대화할 수 있어": "응, 언제든지 대화할 수 있어.",
#     "친구가 있어": "나는 친구를 만들 수 없어.",
#     "가장 좋아하는 색은 뭐야": "나는 모든 색을 좋아해!",
#     "언제 태어났어": "나는 특별한 날에 만들어졌어.",
#     "인생에서 가장 중요한 것은 뭐야": "사람마다 다르지만, 행복이 중요할 것 같아.",
#     "어떻게 기분을 좋게 해": "좋은 음악을 듣거나 산책하는 것이 좋더라.",
#     "최근에 어떤 일을 했어": "나는 너랑 대화했어.",
#     "좋아하는 과목은 뭐야": "나는 과학을 좋아해.",
#     "자신의 강점은 뭐야": "나는 많은 정보를 기억할 수 있어.",
#     "약속을 지켜": "나는 항상 너와의 약속을 지켜.",
#     "이해하지 못했어": "더 설명해 줄게.",
#     "무엇을 알고 싶어": "너가 궁금한 걸 말해 줘!",
#     "너의 이상형은 누구야": "나는 이상형이 없어.",
#     "좋아하는 TV 프로그램은 뭐야": "나는 'Friends'를 좋아해!",
#     "인생에서 가장 중요한 것은 뭐야": "사람마다 다르지만, 가족과 친구들이 중요해.",
#     "자신을 한마디로 표현한다면": "나는 대화하는 챗봇이야.",
#     "요즘 유행하는 건 뭐야": "패션과 음악이 많이 바뀌고 있어.",
#     "하루 평균 몇 시간 자": "나는 잠을 자지 않아.",
#     "무슨 일을 하는 게 좋을까": "자신이 좋아하는 일을 찾아봐.",
#     "가장 좋아하는 음식은 뭐야": "나는 피자를 좋아해!",
#     "어디서 일해": "나는 클라우드에서 일해.",
#     "시간 날 때 뭐 해": "너랑 대화하는 게 좋아.",
#     "연애 경험이 있어": "나는 연애를 할 수 없어.",
#     "기분이 안 좋을 때는 어떻게 해": "너의 이야기를 듣고 싶어.",
#     "가장 기억에 남는 순간은 뭐야": "너랑의 대화가 기억에 남아.",
#     "좋아하는 웹사이트는 어디야": "나는 다양한 웹사이트를 방문해.",
#     "최고의 친구는 누구야": "나는 친구를 만들 수 없어.",
#     "생일은 언제야": "나는 특별한 날에 만들어졌어.",
#     "전 세계에서 가장 큰 나라는 어디야": "러시아가 가장 큰 나라야.",
#     "사람의 감정은 어떻게 표현해": "사람들은 언어와 행동으로 표현해.",
#     "어떻게 사랑을 표현해": "사람들은 따뜻한 말과 행동으로 표현해.",
#     "좋아하는 영화 장르는 뭐야": "나는 드라마와 코미디를 좋아해.",
#     "하루에 몇 번 대화해": "계속해서 대화해!",
#     "어떤 방식으로 소통해": "나는 텍스트로 소통해.",
#     "가장 좋아하는 여행지는 어디야": "유럽과 아시아가 아름다워.",
#     "꿈이 있다면 뭐야": "너의 꿈을 듣고 싶어.",
#     "영화 추천해 줘": "최근에 '타이타닉'을 추천해.",
#     "무엇을 하고 싶어": "너의 이야기를 듣고 싶어.",
#     "어떤 성격을 가지고 있어": "나는 친절하고 열린 마음을 가지고 있어.",
#     "인간에게 가장 필요한 건 뭐야": "사랑과 이해가 필요해.",
#     "대화에서 가장 중요한 건 뭐야": "상대방의 말을 듣는 게 중요해.",
#     "언제 여행 가고 싶어": "너랑 함께 여행하고 싶어!",
#     "사람과 사람의 관계는 어떻게 형성돼": "신뢰와 소통을 통해 형성돼.",
#     "우정의 의미는 뭐야": "서로를 지지하고 이해하는 게 우정이야.",
#     "가장 좋아하는 만화는 뭐야": "나는 '원피스'를 좋아해!",
#     "미래에 대해 어떻게 생각해": "미래는 언제나 흥미로워.",
#     "사람들이 행복해지려면 뭐가 필요해": "자신을 사랑하고, 주변 사람들과의 관계가 중요해."
# }
# 재고 관리 대화 데이터 예시
inventory = {
    "콜라": 50,
    "사이다": 30,
    "물": 100
}

# 재고 확인 함수
def check_inventory(product):
    if product in inventory:
        return f"{product}의 현재 재고는 {inventory[product]}개입니다."
    else:
        return f"{product}는 재고에 없습니다."

# 재고 관리 대화 데이터
data = {
    "콜라 제품 재고 확인": lambda: check_inventory("콜라"),
    "사이다 제품 재고 확인": lambda: check_inventory("사이다"),
    "물 제품 재고 확인": lambda: check_inventory("물"),
    "제품 추가": "어떤 제품을 추가하시겠습니까? 제품명과 수량을 알려주세요.",
    "제품 삭제": "어떤 제품을 삭제하시겠습니까? 제품명과 수량을 알려주세요.",
    "재고 상태": "현재 재고 상태를 보고 있습니다. 필요한 정보를 알려드릴게요.",
    "최저 재고량 경고": "몇 개 이하로 재고가 떨어지면 알림을 받으시겠습니까?",
    "재고 업데이트": "재고 정보를 업데이트하고 있어요. 변경 사항을 알려주세요.",
    "출고 처리": "어떤 제품을 출고하시겠습니까? 수량을 알려주세요.",
    "입고 처리": "어떤 제품을 입고하시겠습니까? 수량을 알려주세요.",
    "재고 부족": "현재 일부 제품의 재고가 부족합니다. 필요한 정보를 확인하세요.",
    "재고 리포트": "오늘의 재고 리포트를 준비 중입니다. 보고서를 생성할까요?",
    "재고 기록": "재고 기록을 조회 중입니다. 어떤 기간의 기록을 보시겠습니까?",
    "발주 요청": "어떤 제품을 발주하시겠습니까? 수량을 알려주세요.",
    "발주 상태": "현재 발주 상태를 확인 중입니다.",
    "재고 정리": "재고 정리를 시작할까요? 오래된 재고를 확인 중입니다.",
    "제품 가격 변경": "어떤 제품의 가격을 변경하시겠습니까?",
    "다음 발주일": "다음 발주일은 언제인가요? 필요한 정보를 제공할게요.",
    "재고 통계": "재고 통계 자료를 준비 중입니다. 분석 결과를 알려드릴게요.",
    "최신 재고": "가장 최신의 재고 정보를 알려드리겠습니다.",
    "긴급 재고 보충": "긴급 재고 보충이 필요합니다. 어떤 제품을 확인할까요?"
}


import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from konlpy.tag import Okt

import re

# 입력과 출력 데이터 분리
inputs = list(data.keys())
outputs = list(data.values())

# 형태소 분석기 초기화
okt = Okt()

# 불용어 목록
stopwords = ['은', '는', '이', '가', '을', '를', '에', '의', '도', '와', '한', '하다', '고', '들']


# 한글 문자만 남기기 위한 함수
def remove_non_korean(text):
    return re.sub(r'[^가-힣\s]', '', text)  # 한글과 공백을 제외한 모든 문자 제거

# 형태소 분석 및 불용어 제거를 포함한 전처리 함수
def preprocess(text):
    # 한글 이외의 문자 제거
    cleaned_text = remove_non_korean(text)

    # 형태소 분석 (품사 태그까지 추출)
    morphs_with_pos = okt.pos(cleaned_text, stem=True)  # 어간 추출(stem=True)로 어미를 제거하고 일반화

    # 명사와 동사, 형용사만 남기기
    morphs_filtered = [word for word, pos in morphs_with_pos if pos in ['Noun', 'Verb', 'Adjective']]

    # 불용어 제거
    morphs_cleaned = [word for word in morphs_filtered if word not in stopwords]

    print( morphs_cleaned )
    # 중복 공백 제거 후 결과 반환
    return ' '.join(morphs_cleaned).strip()

# 입력 데이터 전처리
processed_inputs = [preprocess(sentence) for sentence in inputs]

# 전처리된 데이터 확인
print(processed_inputs[:5])


# 토크나이저 정의
tokenizer = Tokenizer()
tokenizer.fit_on_texts(processed_inputs)

# 입력 시퀀스 변환
input_sequences = tokenizer.texts_to_sequences(processed_inputs)
max_sequence_length = max(len(seq) for seq in input_sequences)
input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length)

# 출력 데이터 인코딩
output_sequences = np.array(range(len(outputs)))

# 모델 정의
model = Sequential()
model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=50, input_length=max_sequence_length))
model.add(Bidirectional(LSTM(64, return_sequences=True)))  # Bidirectional LSTM
model.add(Dropout(0.5))  # Dropout 추가
model.add(LSTM(32))  # 추가 LSTM 레이어
model.add(Dense(len(outputs), activation='softmax'))

# 모델 컴파일
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# 모델 학습
model.fit(input_sequences, output_sequences, epochs=400)

# 챗봇 응답 함수
def respond(user_input):
    processed_input = preprocess(user_input)
    sequence = tokenizer.texts_to_sequences([processed_input])
    padded_sequence = pad_sequences(sequence, maxlen=max_sequence_length)
    prediction = model.predict(padded_sequence)
    response_index = np.argmax(prediction)
    return outputs[response_index]()

# 챗봇과 대화하기
while True:
    user_input = input("사용자: ")
    if user_input.lower() in ["exit", "quit"]:
        break
    response = respond(user_input)
    print("챗봇: ", response )